=====================================================================
초기 모델 성능 평가
0)
 EffNet_b4 기본 모델 성능 시험 epoch20, batch16, default learning rate(0.0005) 성능 시험
 결과 -> '정연비'님의 ai connect 제출 결과에 나와있습니다.
=====================================================================
ConvNext_v2 도입
0.5)
 ConvNext_v2 atto, base 훈련 실패(learning rate : default(5.0e-4)
 결과 -> 훈련 실패
1.0) 
 ConvNext_v2 nano data augmentation lr1.0e-4 epoch5 batch16 성능 시험
 결과 -> github page 참고, ai connect에 제출은 안했으나 그때의, prediction.csv 올려둠
=====================================================================
data augmentation 성공 및 평가
1.5) 
 EffNet_b4 data augmentation epoch 3 batch16 성능 시험
 결과 -> '정연비' 님의 ai connect 제출 결과에 나와있습니다.
=====================================================================
data augmentation 적용 시험 평가
2)
 ConvNext_v2 nano data augmentation lr9.0e-5 epoch20 batch16 성능 시험
 결과 -> public score 0.9077, private score 0.9042, final score 0.9052
=====================================================================
모델 크기에 따른 성능 시험
3)
 ConvNext_v2 nano epoch10 batch16 lr9.0e-5 성능 시험
 결과 -> public score 0.8311 private score 0.8142 final score 0.8193
4)
 ConvNext_v2 base epoch10 batch16 lr9.0e-5 성능 시험
 결과 -> public score 0.8438 private score 0.8465 final score 0.8457
5)
 ConvNext_v2 large epoch10 batch8(gpu memory limit) lr9.0e-5 성능 시험
 결과 -> public score 0.8160 private score 0.8312 final score 0.8267
 
 base가 가장 적당한 것으로 보인다.
=====================================================================
최고 모델 성능 시험
6)
 ConvNext_v2 base epoch20 data augmentation batch16 lr9.0e-5 성능 시험
 결과 -> public score 0.9134 private score 0.9117 final score 0.9122
=====================================================================
learning rate 변경 시험
7)
 ConvNext_v2 nano learning rate 1.0e-4, 2.0e-4, lr7.0e-5 epoch10 성능 시험
 결과 -> 1.0e-4 : public score 0.7696, private score 0.7804 final score 0.7772
 		 -> 2.0e-4 : public score 0.7766, private score 0.7998 final score 0.7928
 		 -> 7.0e-5 : public score 0.7858, private score 0.7857 final score 0.7858
 		 -? 9.0e-5 : public score 0.8311  private score 0.8142 final score 0.8193
	
	9.0e-5가 가장 적당한 것으로 보인다.
======================================================================
classifier 변경 시험(더 무겁거나, 가볍게) (heavier, lighter)

8) 
 updated classier with data augmentation epoch 10 lr9.0e-5 batch 16
 결과 -> public score 0.8808 private score 0.8799 final score 0.8801

8.5)
 classifier 변경 (no augmentation, lr9.0e-5, batch16) convnext_v2 nano 성능 시험
 결과 -> 모두 github page에 올려놨습니다. prediction.csv 파일 있으니 제출해보세요
 
 default로 사용해 왔던것이 가장 좋은 걸로 들어남.
======================================================================
batch_size 32시도

9)
 ConvNext_v2 atto는 batch size 32에도 gpu limit에 걸리지 않음. lr9.0e-5 epoch20 batch32 no augmentation 성능 시험
 결과 -> github page에 올려놨습니다. prediction.csv 파일 있으니 제출해보세요
 
	크기가 atto여서 모델 성능 향상에 한계
======================================================================
6-way data augmentation

10)
  ConvNext_v2_atto_epoch10_lr9.0e-5_4way_augmented vs
  ConvNext_v2_atto_epoch10_lr9.0e-5_6way_augmented result
 결과 -> github에 모두 올라와 있으니 참고 바람. 사실상 차이를 관찰하기 어려움
 

10.5)
	ConvNext_v2_nano_epoch20_lr9.0e-5_6way_augmented vs
	ConvNext_v2_nano_epoch20_lr9.0e-5_4way_augmented result
 결과 -> 6way result : public score 0.9025, private score 0.9087, final score 0.9068
 		 -> 4way result : public score 0.9077, private score 0.9042, final score 0.9052
     많은 연산량 차이에 비해서 결과 차이가 적다.
=====================================================================
tpu 사용해서 실험해 보기

11)
	ConvNext_v2_nano_epoch10_lr9.0e-5_batch16*8_4way_augmentation
	결과 -> public score 0.8543 private score 0.8622 final score 0.8598
	
11.5)
	ConvNext_v2_nano_epoch10_lr2.0e-4_batch16*8_4way_augmentation
	결과 -> public score 0.8907 private score 0.8801 final score 0.8832

12)
	ConvNext_v2_nano_epoch10_lr3.0e-4_batch16*8_4way_augmentation
	결과 -> public score 0.8734 private score 0.8700 final score 0.8710
	
12.5)
	ConvNext_v2_nano_epoch10_lr1.0e-4_batch16*8_4way_augmentation
	결과 -> public score 0.8592 private score 0.8545 final score 0.8559

	같은 세팅에서 gpu에 비해 성능이 떨어진다. lr을 조절해 봐야할 것 같다.
====================================================================
train+valid (validation데이터 사용하지 않고 train이랑 합치기)

13)
	ConvNext_v2_nano_epoch10_lr9.0e-5_batch16_4way_augmentation_train+valid
	결과 -> public score 0.9126 private score 0.9224 final score 0.9195
	
13.5)
	ConvNext_v2_nano_epoch20_lr9.0e-5_batch16_6way_augmentation_train+valid
	결과 -> public score 0.9368 private score 0.9378 final score 0.9375

14)
	ConvNext_v2_nano_epoch20_lr9.0e-5_batch16_9way_augmentation_train+valid
	결과 -> public score 0.9458, private score 0.9428 final score 0.9437

14.5)
	ConvNext_v2_atto_epoch20_lr9.0e-5_batch256_9way_augmentation_train+valid
	결과 -> public score 0.9354 private score 0.9359 final score 0.9358 
	
15)
 	ConvNext_v2_nano_epoch20_lr9.0e-5_batch128_9way_augmentation_train+valid
 	결과 -> public score 0.
 	
15.5)
	ConvNext_v2_base_epoch17_lr9.0e-5_batch24_9way_augmentation_train+valid
   결과 -> public score 0.9419, private score 0.9384, final score 0.9395
 

모두 github page에 training history 자료들이 존재하니, ppt 만들 때 참고 가능.
따로 augmentation에 대한 언급이 없으면, 데이터 증강이 적용되지 않은 버전입니다.
 
 
 
	
